{"task_name": "banking77", "train_file": null, "validation_file": null, "max_train_samples": null, "max_length": 128, "pad_to_max_length": false, "model_name_or_path": "gpt-j-6B", "load_init_model": false, "save_init_model": false, "ckpt_path": "ckpt", "lr": 0.001, "weight_decay": 0.1, "num_train_epochs": 40, "max_train_steps": null, "gradient_accumulation_steps": 1, "lr_scheduler_type": "cosine", "num_warmup_steps": 200, "output_dir": "outputs_best/banking77/full/gpt-j-6B", "overwrite_output_dir": true, "seed": 7, "ds_config": {"train_micro_batch_size_per_gpu": 16, "gradient_accumulation_steps": 1, "allgather_bucket_size": 200000000.0, "reduce_bucket_size": 200000000.0, "steps_per_print": 100, "fp16": {"enabled": "auto", "min_loss_scale": 1}, "zero_allow_untested_optimizer": true, "zero_optimization": {"stage": 2, "allgather_partitions": true, "allgather_bucket_size": 200000000.0, "reduce_scatter": true, "reduce_bucket_size": 200000000.0, "overlap_comm": true, "contiguous_gradients": true, "cpu_offload": false}}, "local_rank": 0, "apply_lora": true, "lora_alpha": 16, "lora_r": 13, "apply_prefix": false, "num_prefix": 10, "mid_dim": 16, "apply_adapter": false, "adapter_size": 2, "adapter_type": "houlsby", "apply_encoder": false, "apply_input": false, "encoder_model_name_or_path": "gpt2", "freeze_encoder": false, "apply_prompt": false, "prompt_length": null, "reparameterize": false, "cache_dir": "/home/pch330/data/model_data", "apply_linear": false, "split": true, "split_ratio": 0.25, "lr_ratio": 0.2, "per_device_batch_size": 16, "is_zero3": false, "world_size": 2}